import pandas as pd
import requests
import logging
import os
import json
import time
import re
from pathlib import Path
from typing import List, Dict, Optional
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ================= 配置日志系统 =================
# 创建日志目录
log_dir = Path("output/logs")
log_dir.mkdir(parents=True, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_dir / "vulnerability_code_extractor.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class IntegratedVulnMiner:
    """
    终极漏洞挖掘器
    核心修复：
    1. 动态搜索：解决 Buggy/Fixed 版本行号不一致问题。
    2. NaN 清洗：解决 signature: NaN 问题。
    3. 缺失标记：准确标记新增函数。
    4. 单文件存储：批量结果存入一个 JSON。
    """
    
    NVD_BASE_URL = "https://services.nvd.nist.gov/rest/json/cves/2.0"

    def __init__(self, repo_root: str, nvd_api_key: Optional[str] = None):
        self.root = Path(repo_root)
        self.project_csv = self.root / "data" / "project_info.csv"
        self.fix_info_csv = self.root / "data" / "fix_info.csv"
        
        # 结果保存配置
        self.output_dir = Path("output/vulnerability_code")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.combined_file_path = self.output_dir / "all_cves_combined.json"

        # 网络配置
        self.api_key = nvd_api_key
        self.headers = {"User-Agent": "Mozilla/5.0", "Accept": "application/json"}
        self.nvd_delay = 1.0 if self.api_key else 6.0
        
        self.session = requests.Session()
        retries = Retry(total=5, backoff_factor=1, status_forcelist=[500, 502, 503, 504])
        self.session.mount('https://', HTTPAdapter(max_retries=retries))

        # 加载数据
        logger.info("正在加载 CSV 数据表...")
        try:
            self.df_project = pd.read_csv(self.project_csv)
            self.df_fix = pd.read_csv(self.fix_info_csv)
            logger.info(f"数据加载完成。项目总数: {len(self.df_project)}")
        except Exception as e:
            logger.error(f"加载 CSV 失败: {e}")
            raise

    # ================= 1. NVD 信息获取 =================
    def fetch_nvd_info(self, cve_id: str) -> Dict:
        cve_id = cve_id.strip().upper()
        
        empty_info = {
            "description": "N/A",
            "published_date": None,
            "cvss_v3_score": None,
            "severity": None
        }

        try:
            time.sleep(self.nvd_delay)
            resp = self.session.get(self.NVD_BASE_URL, headers=self.headers, params={"cveId": cve_id}, timeout=30)
            
            if resp.status_code == 200:
                data = resp.json()
                vulns = data.get("vulnerabilities", [])
                if not vulns: return empty_info
                
                cve_item = vulns[0].get("cve", {})
                
                # 提取描述
                desc = "No description"
                for d in cve_item.get("descriptions", []):
                    if d.get("lang") == "en":
                        desc = d.get("value")
                        break
                
                # 提取评分
                metrics = cve_item.get("metrics", {})
                cvss_data = metrics.get("cvssMetricV31", [])
                score = None
                severity = None
                if cvss_data:
                    metric_data = cvss_data[0].get("cvssData", {})
                    score = metric_data.get("baseScore")
                    severity = metric_data.get("baseSeverity")

                return {
                    "description": desc,
                    "published_date": cve_item.get("published"),
                    "cvss_v3_score": score,
                    "severity": severity
                }
        except Exception:
            pass
            
        return empty_info

    # ================= 2. GitHub 代码下载 =================
    def fetch_github_lines(self, github_url: str, commit_id: str, file_path: str) -> List[str]:
        if not isinstance(github_url, str): return []
        clean_url = github_url.rstrip("/").replace(".git", "")
        parts = clean_url.split("/")
        if len(parts) < 2: return []
        
        raw_url = f"https://raw.githubusercontent.com/{parts[-2]}/{parts[-1]}/{commit_id}/{file_path}"
        
        time.sleep(0.3)
        try:
            resp = self.session.get(raw_url, timeout=20)
            if resp.status_code == 200:
                return resp.text.splitlines(keepends=True)
        except: pass
        return []

    # ================= 3. 动态搜索算法 (核心) =================
    def _find_method_in_buggy_file(self, lines: List[str], method_name: str, hint_line: int) -> int:
        """
        在 Buggy 文件中搜索函数定义的起始行。
        策略：优先在 hint (CSV提供的行号) 附近找，找不到则全文件搜。
        """
        # 搜索范围：hint 上下 100 行
        start_search = max(0, hint_line - 100)
        end_search = min(len(lines), hint_line + 100)
        
        def is_method_def(line, name):
            # 简单启发式：包含名字 + 左括号 + 不是分号结尾(除非有大括号)
            if name not in line: return False
            if "(" not in line: return False
            if ";" in line and "{" not in line: return False
            return True

        # 1. 局部搜索 (命中率高)
        for i in range(start_search, end_search):
            if is_method_def(lines[i], method_name):
                return i
        
        # 2. 全局搜索 (兜底)
        for i in range(len(lines)):
            if is_method_def(lines[i], method_name):
                return i
                
        return -1 # 彻底没找到

    def extract_code_snippets(self, project_slug: str, github_url: str, buggy_commit: str) -> List[Dict]:
        snippets = []
        fixes = self.df_fix[self.df_fix['project_slug'] == project_slug]
        
        if fixes.empty: return snippets

        for idx, row_fix in fixes.iterrows():
            if pd.isna(row_fix['file']): continue
            file_path = row_fix['file']
            
            method_name = row_fix['method']
            if pd.isna(method_name): method_name = "unknown"

            # === [清洗] 处理 NaN 问题 (解决 signature: NaN) ===
            raw_class = row_fix.get('class')
            if pd.isna(raw_class):
                class_name = Path(file_path).stem 
            else:
                class_name = str(raw_class).strip()

            raw_sig = row_fix.get('signature')
            if pd.isna(raw_sig):
                signature = None # 显式设为 None，JSON 中为 null
            else:
                signature = str(raw_sig).strip()
            # ===============================================

            # 获取 CSV 里的行号作为“线索” (Hint)
            try:
                hint_start = int(row_fix['method_start'])
                csv_end = int(row_fix['method_end'])
            except: 
                hint_start = 0
                csv_end = 0

            # 1. 下载 Buggy 代码
            lines = self.fetch_github_lines(github_url, buggy_commit, file_path)
            
            base_info = {
                "file_path": file_path,
                "class_name": class_name,
                "method_name": method_name,
                "signature": signature,
                "lines_hint_csv": [hint_start, csv_end], # 仅作记录参考
            }

            if not lines:
                base_info.update({
                    "code": "",
                    "is_missing_in_buggy_version": True,
                    "status": "FILE_MISSING"
                })
                snippets.append(base_info)
                continue

            # 2. 动态搜索函数位置 (不依赖 CSV 行号)
            # hint_start 是 1-based，转 0-based 需要 -1
            found_idx = self._find_method_in_buggy_file(lines, method_name, hint_start - 1)

            if found_idx == -1:
                # 真的没找到 -> 说明是新增函数
                base_info.update({
                    "code": "",
                    "is_missing_in_buggy_version": True,
                    "status": "METHOD_MISSING"
                })
                snippets.append(base_info)
                continue

            # 3. 从找到的头开始，向下寻找平衡的大括号
            real_start_idx = found_idx
            real_end_idx = real_start_idx
            balance = 0
            found_brace = False
            
            for i in range(real_start_idx, len(lines)):
                line = lines[i]
                opens = line.count('{')
                closes = line.count('}')
                
                if opens > 0: found_brace = True
                balance += (opens - closes)
                real_end_idx = i
                
                # 只要找到了起始大括号，且平衡归零，就结束
                if found_brace and balance == 0:
                    break
            
            e_idx = real_end_idx + 1
            code_str = "".join(lines[real_start_idx:e_idx])

            # 4. 组装结果
            base_info.update({
                "code": code_str,
                "is_missing_in_buggy_version": False,
                "status": "FOUND",
                "lines_extracted": [real_start_idx + 1, e_idx]
            })
            snippets.append(base_info)
            
        return snippets

    # ================= 4. 数据生成逻辑 =================
    def generate_single_cve_data(self, row_project) -> Optional[Dict]:
        cve_id = row_project['cve_id']
        project_slug = row_project['project_slug']
        
        # logger.info(f"正在处理: {cve_id}") # 减少日志刷屏
        
        nvd_info = self.fetch_nvd_info(cve_id)
        snippets = self.extract_code_snippets(
            project_slug, 
            row_project['github_url'], 
            row_project['buggy_commit_id']
        )
        
        if not snippets and nvd_info['description'] == "N/A":
            return None

        return {
            "cve_id": cve_id,
            "project_slug": project_slug,
            "buggy_commit_id": row_project['buggy_commit_id'],
            "github_url": row_project['github_url'],
            "nvd_metadata": nvd_info,
            "code_snippets": snippets
        }

    # ================= 5. 运行模式 =================
    def run_interactive(self):
        print("\n--- 单个查询模式 ---")
        while True:
            cve_input = input("\n请输入 CVE 号 (q 退出): ").strip().upper()
            if cve_input == 'Q': break
            
            projects = self.df_project[self.df_project['cve_id'] == cve_input]
            if projects.empty:
                print("❌ 数据集中未找到该 CVE")
                continue
            
            data = self.generate_single_cve_data(projects.iloc[0])
            if data:
                # 交互模式单独存一个文件方便看
                p = self.output_dir / f"debug_{cve_input}.json"
                with open(p, "w", encoding="utf-8") as f:
                    json.dump(data, f, indent=2, ensure_ascii=False)
                print(f"✅ 提取成功: {p}")
            else:
                print("⚠️ 无效数据")

    def run_batch(self):
        total = len(self.df_project)
        print(f"\n--- 批量全量处理 ---")
        print(f"所有结果将存入: {self.combined_file_path}")
        print("支持断点续传。")
        
        if input("确认开始? (y/n): ").lower() != 'y': return

        # 断点续传逻辑
        all_data = []
        processed_ids = set()
        
        if self.combined_file_path.exists():
            try:
                print("正在加载历史数据...")
                with open(self.combined_file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                    if content.strip():
                        all_data = json.loads(content)
                        processed_ids = {item['cve_id'] for item in all_data}
                print(f"已加载 {len(all_data)} 条记录。")
            except Exception as e:
                logger.error(f"历史文件读取失败: {e}")
                all_data = []

        success_count = 0
        skip_count = 0

        for index, row in self.df_project.iterrows():
            cve_id = row['cve_id']
            
            if cve_id in processed_ids:
                print(f"[{index + 1}/{total}] {cve_id} 跳过")
                skip_count += 1
                continue

            print(f"[{index + 1}/{total}] {cve_id} ", end="")
            
            try:
                data = self.generate_single_cve_data(row)
                if data:
                    all_data.append(data)
                    processed_ids.add(cve_id)
                    success_count += 1
                    print("✅")
                else:
                    print("⚠️ 空")

                # 每5个保存一次
                if success_count > 0 and success_count % 5 == 0:
                    with open(self.combined_file_path, "w", encoding="utf-8") as f:
                        json.dump(all_data, f, indent=2, ensure_ascii=False)
            
            except Exception as e:
                print(f"❌ {e}")
                logger.error(f"Error {cve_id}: {e}")

        # 最终保存
        with open(self.combined_file_path, "w", encoding="utf-8") as f:
            json.dump(all_data, f, indent=2, ensure_ascii=False)
        
        print("\n" + "="*30)
        print(f"处理完成! 成功: {success_count}, 跳过: {skip_count}, 总计: {total}")

if __name__ == "__main__":
    # === 使用统一配置模块 ===
    try:
        from config import get_repo_root, get_nvd_api_key
    except ImportError:
        # 如果 config.py 不存在，使用自动检测
        import os
        current_dir = os.path.dirname(os.path.abspath(__file__))
        parent_dir = os.path.dirname(current_dir)
        if os.path.exists(os.path.join(parent_dir, "data", "project_info.csv")):
            REPO_ROOT = parent_dir
        else:
            REPO_ROOT = None
        MY_API_KEY = None
    else:
        REPO_ROOT = get_repo_root()
        MY_API_KEY = get_nvd_api_key()
    
    if not REPO_ROOT or not os.path.exists(REPO_ROOT):
        print(f"❌ 路径不存在或未配置: {REPO_ROOT}")
        print("\n请使用以下方式之一配置项目根路径：")
        print("  1. 设置环境变量: CWE_BENCH_JAVA_ROOT")
        print("  2. 创建 tools/config.json 文件，设置 repo_root")
        print("  3. 运行 python tools/config.py 创建配置模板")
        exit(1)
    
    miner = IntegratedVulnMiner(REPO_ROOT, nvd_api_key=MY_API_KEY)
    while True:
        c = input("\n1.单查 / 2.批量 / q.退出: ").strip().lower()
        if c == '1': miner.run_interactive()
        elif c == '2': miner.run_batch()
        elif c == 'q': break