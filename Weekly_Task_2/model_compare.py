import os
import json
import random
import numpy as np
import torch
from sentence_transformers import CrossEncoder

# 1. è®¾ç½®é•œåƒåŠ é€Ÿ
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

# è¾…åŠ©å‡½æ•°
def format_context_input(item):
    """
    å¸¦ä¸Šä¸‹æ–‡çš„è¾“å…¥æ ¼å¼ï¼šæ¶ˆè€— token ç”¨äºæä¾›å…ƒæ•°æ®
    """
    return f"File: {item['path']}\nMethod: {item['method']}\nCode:\n{item['code']}"

def clean_code_input(item):
    """
    çº¯ä»£ç è¾“å…¥æ ¼å¼ï¼šå°½å¯èƒ½å¤šåœ°ä¿ç•™ä»£ç é€»è¾‘
    """
    return item['code'].strip()

def select_best_snippet(cve_item):
    """
    æ™ºèƒ½é€‰æ‹© Ground Truth (ä¿æŒä¸å˜)
    """
    snippets = cve_item.get('code_snippets', [])
    description = cve_item['nvd_metadata']['description'].lower()
    
    best_snippet = None
    max_score = -100
    
    risk_keywords = ["unzip", "extract", "parse", "eval", "exec", "query", "validate", "sanitize", "deserialize"]
    generic_keywords = ["file", "run", "main", "setup", "teardown", "test", "dummy", "get", "set"]

    for s in snippets:
        if not s.get('code', '').strip(): continue
        method_name = s['method_name']
        m_name_lower = method_name.lower()
        score = 0
        
        if m_name_lower in description and len(m_name_lower) > 3: score += 10
        if any(k in m_name_lower for k in risk_keywords): score += 5
        if any(k == m_name_lower for k in generic_keywords): score -= 10
        score += min(len(s['code']) / 1000, 2)
        if "test" in s.get('file_path', '').lower(): score -= 2
        
        if score > max_score:
            max_score = score
            best_snippet = s
            
    if not best_snippet and snippets:
        best_snippet = next((s for s in snippets if s.get('code', '').strip()), None)
    return best_snippet

# ä¸»ç¨‹åº

current_dir = os.path.dirname(os.path.abspath(__file__))
json_path = os.path.join(current_dir, 'final_dataset', 'all_cves_combined.json')

print(f"ğŸ“‚ è¯»å–æ•°æ®: {json_path}")
try:
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
except Exception as e:
    print(f"âŒ è¯»å–å¤±è´¥: {e}")
    exit()

# æ•°æ®æ¸…æ´—
valid_cves = []
for item in data:
    valid_snippets = [s for s in item.get('code_snippets', []) if not s.get('is_missing_in_buggy_version', False) and s.get('code', '').strip()]
    if valid_snippets:
        item['code_snippets'] = valid_snippets
        valid_cves.append(item)

if not valid_cves:
    print("âŒ æ•°æ®é›†ä¸ºç©ºï¼")
    exit()

print(f"âœ… æœ‰æ•ˆæ ·æœ¬æ•°: {len(valid_cves)}")

# 4. åŠ è½½æ¨¡å‹
print("\n æ­£åœ¨åŠ è½½æ¨¡å‹ç¾¤...")
device = "cuda" if torch.cuda.is_available() else "cpu"

# æ¨¡å‹ A: Baseline
print(f"   ğŸ”¹ æ¨¡å‹ A (Base): ms-marco-MiniLM-L-6-v2")
model_base = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', max_length=512, device=device)

# æ¨¡å‹ B: CodeBERT (æˆ‘ä»¬å°†ç”¨å®ƒè·‘ä¸¤éï¼šä¸€éå¸¦Contextï¼Œä¸€éä¸å¸¦)
print(f"   ğŸ”¹ æ¨¡å‹ B (Code): codebert-cross-encoder (Shared for Ctx/Raw)")
model_codebert = CrossEncoder('alexandraroze/codebert-cross-encoder', max_length=512, device=device)

# æ¨¡å‹ C: BGE-M3
print(f"   ğŸ”¹ æ¨¡å‹ C (BGE ): bge-reranker-v2-m3")
model_args = {'torch_dtype': torch.float16} if device == "cuda" else {}
model_bge = CrossEncoder('BAAI/bge-reranker-v2-m3', max_length=1024, automodel_args=model_args, device=device)

# ==========================================
# 5. å¯¹æ¯”æµ‹è¯•å¾ªç¯
# ==========================================
NUM_ROUNDS = 10 
test_cases = random.sample(valid_cves, min(NUM_ROUNDS, len(valid_cves)))

print(f"\n æ¯”è¾ƒå¼€å¯! (Code-Ctx = å¸¦å‰ç¼€, Code-Raw = çº¯ä»£ç )\n")
# è¡¨å¤´è°ƒæ•´
print(f"{'CVE ID':<14} | {'Base':<4} | {'Code-Ctx':<8} | {'Code-Raw':<8} | {'BGE':<4} | {'Winner':<8}")
print("-" * 75)

# è®°å½•æ’å
ranks = {'base': [], 'code_ctx': [], 'code_raw': [], 'bge': []}

for cve in test_cases:
    cve_id = cve['cve_id']
    query = cve['nvd_metadata']['description']
    
    # å‡†å¤‡æ ·æœ¬
    target = select_best_snippet(cve)
    if not target: continue
    
    candidates = [{'code': target['code'], 'method': target['method_name'], 'path': target['file_path'], 'label': 'True'}]
    
    others = [x for x in valid_cves if x['cve_id'] != cve_id]
    distractors = random.sample(others, min(9, len(others)))
    for d in distractors:
        ds = random.choice(d['code_snippets'])
        candidates.append({'code': ds['code'], 'method': ds['method_name'], 'path': ds['file_path'], 'label': 'False'})
        
    random.shuffle(candidates)
    
    # --- æ„é€ è¾“å…¥ ---
    # 1. çº¯ä»£ç è¾“å…¥ (Base & Code-Raw)
    inputs_raw = [[query, clean_code_input(item)] for item in candidates]
    
    # 2. å¸¦ä¸Šä¸‹æ–‡è¾“å…¥ (Code-Ctx & BGE)
    inputs_ctx = [[query, format_context_input(item)] for item in candidates]
    
    # --- æ¨ç† ---
    scores_base = model_base.predict(inputs_raw)
    scores_code_ctx = model_codebert.predict(inputs_ctx)      # CodeBERT æ–¹æ¡ˆ1
    scores_code_raw = model_codebert.predict(inputs_raw)      # CodeBERT æ–¹æ¡ˆ2
    scores_bge = model_bge.predict(inputs_ctx)
    
    # --- æ’åè®¡ç®— ---
    def get_rank(scores, candidates):
        ranked_indices = np.argsort(scores)[::-1]
        for r, idx in enumerate(ranked_indices):
            if candidates[idx]['label'] == 'True': return r + 1
        return -1

    r_base = get_rank(scores_base, candidates)
    r_ctx = get_rank(scores_code_ctx, candidates)
    r_raw = get_rank(scores_code_raw, candidates)
    r_bge = get_rank(scores_bge, candidates)
    
    ranks['base'].append(r_base)
    ranks['code_ctx'].append(r_ctx)
    ranks['code_raw'].append(r_raw)
    ranks['bge'].append(r_bge)
    
    # åˆ¤å®šæœ¬è½®èƒœè€…
    best_rank = min(r_base, r_ctx, r_raw, r_bge)
    winners = []
    if r_base == best_rank: winners.append("Base")
    if r_ctx == best_rank: winners.append("Ctx")
    if r_raw == best_rank: winners.append("Raw")
    if r_bge == best_rank: winners.append("BGE")
    
    print(f"{cve_id:<14} | {r_base:<4} | {r_ctx:<8} | {r_raw:<8} | {r_bge:<4} | {'/'.join(winners):<8}")

# ==========================================
# 6. æœ€ç»ˆç»Ÿè®¡
# ==========================================
def print_stats(name, r_list):
    mrr = np.mean([1/r for r in r_list])
    avg = np.mean(r_list)
    print(f"{name:<20} | {avg:<15.2f} | {mrr:<15.2f}")

print("-" * 75)
print("\nğŸ“Š æœ€ç»ˆç»“æœ:")
print(f"{'Model Configuration':<20} | {'Avg Rank (â†“)':<15} | {'MRR (â†‘)':<15}")
print("-" * 55)
print_stats("Baseline (MiniLM)", ranks['base'])
print_stats("CodeBERT (Context)", ranks['code_ctx'])
print_stats("CodeBERT (Raw)", ranks['code_raw'])
print_stats("BGE-M3 (SOTA)", ranks['bge'])
print("-" * 55)